trigger:
  - master
pr:
  - none

resources:
  repositories:
    - repository: templates
      type: github
      name: hmcts/azure-devops-templates
      ref: refs/heads/master
      endpoint: hmcts

parameters:
  - name: environment
    displayName: Environment to Deploy (sbox default)
    type: string
    default: sandbox
    values:
      - dev
      - sandbox
      - test1
      - test2
      - demo
      - aat
      - preview

variables:
  - group: vh-reporting-infra

stages:

  - stage: CIBuild
    displayName: 'Validate Infra'
    jobs: 
      - template: pipeline/jobs/terraform-validate.yaml
        parameters:
          terraformPath: $(Build.SourcesDirectory)/infrastructure
  
  - stage: Plan
    displayName: Plan ${{ parameters.environment }}
    jobs:
      - template: pipeline/jobs/terraform-plan.yaml
        parameters:
          subscription: $(subscription)
          environment: ${{ parameters.environment }}
          location: $(location)
          resourceGroup: $(resourceGroup)
          storageAccount: $(storageAccount)
          containerName: $(containerName)
          stateKey: $(stateKey)-${{ parameters.environment }}.tfstate
          outputName: ${{ parameters.environment }}
          workingDirectory: $(System.DefaultWorkingDirectory)/infrastructure

  - stage: Wait
    jobs:
      - job: Wait
        displayName: "Wait for approval"
        pool: server
        steps:
          - template: pipeline/steps/wait.yaml
            parameters:
              environment: ${{ parameters.environment }}
            
  - stage: Apply
    displayName: Apply ${{ parameters.environment }}
    dependsOn: Wait 
    jobs:
      - template: pipeline/jobs/terraform-apply.yaml
        parameters:
          subscription: $(subscription)
          dependsOn: Wait
          location: $(location)
          environment: ${{ parameters.environment }}
          resourceGroup: $(resourceGroup)
          storageAccount: $(storageAccount)
          containerName: $(containerName)
          stateKey: $(stateKey)-${{ parameters.environment }}.tfstate
          outputName: ${{ parameters.environment }}
          workingDirectory: $(System.DefaultWorkingDirectory)/infrastructure

  - stage: LogicApp
    displayName: Logic App Config
    dependsOn: Apply
    jobs:
        - job: UpdateLogicApp
          displayName: Update Logic App Workflow
          steps:
            - task: AzureCLI@2
              displayName: Azure CLI
              inputs:
                azureSubscription: Reform-CFT-VH-Dev
                scriptType: bash
                scriptLocation: inlineScript
                inlineScript: |
                  az config set extension.use_dynamic_install=yes_without_prompt
                  az logic workflow create --resource-group vh-reporting-infra-${{ parameters.environment }} --location "uksouth" --name "vh-reporting-${{ parameters.environment }}" --definition "$(System.DefaultWorkingDirectory)/logicApp/appInsightsToStorage.json"

  - stage: ReportingDB
    displayName: Reporting DB Build
    dependsOn: Apply 
    jobs:
       
      - template: pipeline/jobs/db-config.yaml
        parameters: 
          azureSubscription: Reform-CFT-VH-Dev
          environment: ${{ parameters.environment }}
          dbuser: $(dbuser)
          dbuserpass: $(dbuserpass)
          SqlFileName: '00_init.sql'


  - stage: ADF
    displayName: ADF Config
    dependsOn: Apply 
    jobs:
       
        - job: UpdateADFPipelines 
          displayName: Create/Update ADF pipelines
          steps:
            - task: AzureCLI@2
              displayName: Azure CLI
              inputs:
                azureSubscription: Reform-CFT-VH-Dev
                scriptType: bash
                scriptLocation: inlineScript
                inlineScript: |
                  az config set extension.use_dynamic_install=yes_without_prompt
                  ls -ltr $(System.DefaultWorkingDirectory)
                  #set up datasets
                  az datafactory dataset create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "AsqlSource" --properties dataset/AsqlSource.json
                  az datafactory dataset create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "AsqlTarget" --properties dataset/AsqlTarget.json
                  az datafactory dataset create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "JsonAppInsightsError" --properties dataset/JsonAppInsightsError.json
                  az datafactory dataset create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "JsonAppInsightsTrace" --properties dataset/JsonAppInsightsTrace.json
                  #set up pipelines
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Child_AsqlToAsql" --pipeline "pipeline/Child_AsqlToAsql.json"
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Child_StageAppInsightsError" --pipeline "pipeline/Child_StageAppInsightsError.json"
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Child_StageAppInsightsTrace" --pipeline "pipeline/Child_StageAppInsightsTrace.json"
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Master_ErrorFile" --pipeline "pipeline/Master_ErrorFile.json"
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Master_Staging" --pipeline "pipeline/Master_Staging.json"
                  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "Master_TraceFile" --pipeline "pipeline/Master_TraceFile.json"

                  ##TODO fix the below
                  #for file in $(System.DefaultWorkingDirectory)/dataset/*
                  #do
                  #  fileName=$(cut -f 1 -d '.' "$file")
                  #  echo "$fileName"
                  #  az datafactory dataset create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "$fileName" --properties "$file"
                  #done
          

                  ##set up pipelines
                  #for file in $(System.DefaultWorkingDirectory)/pipeline/*
                  #do
                  #  fileName=$(cut -f 1 -d '.' $file)
                  #  az datafactory pipeline create --resource-group vh-reporting-infra-${{ parameters.environment }} --factory-name "vh-datafactory-${{ parameters.environment }}" --name "$fileName" --pipeline "$file"
                  #done
            
